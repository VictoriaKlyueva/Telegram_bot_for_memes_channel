import telebot

import os
import numpy as np

import torch
from transformers import pipeline
import onnxruntime as ort
from diffusers import DDPMScheduler, UNet2DModel

from PIL import ImageFont
from PIL import ImageDraw
from PIL import Image
from io import BytesIO

import random

import codecs

CHANNEL_ID = -1002242343472
TIME_STEPS = 500
IMAGE_SIZE = 256


def import_token(path):
    with open(os.path.join(path, 'token.txt')) as f:
        token = f.read().strip()

    return token


# Make bot session
token = import_token('')
bot = telebot.TeleBot(token)

# Make ort session for GAN
ort_session_gan = ort.InferenceSession('local_models/generator.onnx')

# Load diffusion model and scheduler
scheduler = DDPMScheduler.from_pretrained("google/ddpm-cat-256")
model = UNet2DModel.from_pretrained("google/ddpm-cat-256").to('cpu')

scheduler.set_timesteps(TIME_STEPS)

upload_directory = "local_models/diffuser"
model.from_pretrained(upload_directory)
scheduler.from_pretrained(upload_directory)

print("Модель загружена")

# Making pipeline for transformer
pipe = pipeline(
    'text-generation',
    model='C:/Users/Legion/PycharmProjects/Telegram_bot_for_memes_channel/local_models/gpt-memes',
    tokenizer='ai-forever/rugpt3small_based_on_gpt2',
    max_new_tokens=50,
    truncation=True
)

# Creating folder for generated images and text
if not os.path.isdir("generated_data"):
    os.mkdir("generated_data")


# Get image, generated by GAN
def generate_image():
    random_noise = np.random.randn(1, 100, 1, 1).astype(np.float32)
    # Get model output
    generated_image = ort_session_gan.run(None, {'input_noise': random_noise})
    generated_image = np.array(generated_image[0][0])

    # Swap array dimensions
    generated_image = generated_image.transpose((1, 2, 0))
    # Scale the image pixels back to (0, 255)
    generated_image = (generated_image + 1) * 127.5
    # Convert to uint8 for PIL conversion
    generated_image = generated_image.astype(np.uint8)

    pil_image = Image.fromarray(generated_image)

    # Resize from (64, 64) to (128, 128)
    pil_image = pil_image.resize((256, 256))

    return pil_image


# Get image, generated by diffuser
def generate_diffused_image():
    random_noise = torch.randn((1, 3, IMAGE_SIZE, IMAGE_SIZE))
    input = random_noise

    count = 0
    for t in scheduler.timesteps:
        with torch.no_grad():
            noisy_residual = model(input, t).sample
            prev_noisy_sample = scheduler.step(noisy_residual, t, input).prev_sample
            input = prev_noisy_sample

        print(f'Шаг: {count} / {scheduler.timesteps[0]}')
        count += 1

    # Post-processing
    image = (input / 2 + 0.5).clamp(0, 1)
    image = image.cpu().permute(0, 2, 3, 1).numpy()[0]
    image = Image.fromarray((image * 255).round().astype("uint8"))

    return image


def save_image(image, path):
    # Save the PIL image in the root folder
    image.save(path)


def post_processing(text):
    return text.replace('\n', '').replace('&nbsp;', ' ').split('  ')


def get_prompt():
    path = 'prompts_data/'
    prompts_object = codecs.open(path + "prompts_ideas.txt", "r", "utf_8_sig")
    prompts = prompts_object.read().replace('\r', '').split('\n')

    prompt = random.choice(prompts).split()
    prompt = prompt if len(prompt) <= 3 else prompt[:random.randint(1, 3)]
    prompt = ' '.join(prompt)

    if len(prompt) == 1:
        addition_object = codecs.open(path + "prompts_ideas.txt", "r", "utf_8_sig")
        additions = addition_object.read().replace('\r', '').split('\n')
        addition = random.choice(prompts)

        prompt += ' ' + addition

    return prompt


def generate_text():
    while True:
        prompt = get_prompt()
        result = post_processing(pipe(prompt)[0]['generated_text'])[0]

        if len(result) > len(prompt):
            break
        else:
            print("Генерация продолжается")

    print("Prompt: ", prompt, "Output: ", result)

    if len(result) > 30 and len(result.split()) == 1:
        result = result[:30]

    return result


def add_shadow(text, draw, font, x, y, offset=3, shadow_color='black'):
    for off in range(offset):
        draw.text((x - off, y), text, font=font, fill=shadow_color)
        draw.text((x + off, y), text, font=font, fill=shadow_color)
        draw.text((x, y + off), text, font=font, fill=shadow_color)
        draw.text((x, y - off), text, font=font, fill=shadow_color)
        draw.text((x - off, y + off), text, font=font, fill=shadow_color)
        draw.text((x + off, y + off), text, font=font, fill=shadow_color)
        draw.text((x - off, y - off), text, font=font, fill=shadow_color)
        draw.text((x + off, y - off), text, font=font, fill=shadow_color)


def dynamic_text_position(text):
    # Select font size
    font_size = int(480 / len(text))

    # Select left-bottom of the text
    x = 15
    y = 240 - font_size

    return font_size, x, y


def put_text_on_image(image, text):
    draw = ImageDraw.Draw(image)

    # Select font
    fonts = os.listdir('fonts')
    font_choice = random.choice(fonts)

    # Select color
    color = (255, 255, 255)

    font_size, x, y = dynamic_text_position(text)

    # Import font
    with open('fonts/' + font_choice, "rb") as f:
        bytes_font = BytesIO(f.read())
    font = ImageFont.truetype(bytes_font, font_size)

    # Draw shadow
    add_shadow(text, draw, font, x, y)
    # Draw text
    draw.text((x, y), text, color, font=font)

    return image


@bot.message_handler(content_types=['text', 'image'])
def send_meme(message):
    # Generate image
    print('Начата генерация фото')
    # image = Image.fromarray(np.random.randint(0, 256, (IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.uint8))
    image = generate_diffused_image()
    print('Фото сгенерировано')
    # Generate text
    print('Начата генерация текста')
    text = generate_text()
    print('Текст сгенерирован')

    # Create meme
    meme = put_text_on_image(image, text)

    # Save meme
    path = 'generated_data/generated_meme.png'
    save_image(meme, path)
    print('Мем создан')

    # Send meme
    try:
        file = open(path, 'rb')
        try:
            if message.text != 'мем':
                # bot.send_photo(CHANNEL_ID, file, caption=message.text)
                bot.send_photo(message.chat.id, file, caption=message.text)
            else:
                # bot.send_photo(CHANNEL_ID, file)
                bot.send_photo(message.chat.id, file)
            print("Мем отправлен")
        except Exception as e:
            print("Error sending the photo")
            print(e)
    except Exception as e:
        print("Error reading the file")
        print(e)


# Loop for code execution
bot.infinity_polling(timeout=10, long_polling_timeout=5)
